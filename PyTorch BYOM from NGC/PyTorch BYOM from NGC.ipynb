{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy NGC pytorch model to SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a description of the model you can look here: https://ngc.nvidia.com/catalog/model-scripts/nvidia:ssd_for_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by downloading an SSD model from NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 20:44:19--  https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 54.186.237.130, 52.38.124.212\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|54.186.237.130|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt?response-content-disposition=attachment%3B%20filename%3D%22nvidia_ssdpyt_fp32_190826.pt%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJGMEQCIDTOcIMEjEOZCz8fE8A9VS52BuQxLfxHV5HjD2XMImILAiBBGPC5D%2FBlfMhB%2Bpe4bYj7mYlpOnoeNb4%2FIHSuAQ7Gpiq9Awjd%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMsVQ6WZTk70s2icTCKpED0yPq8kHJUawmVePhsCIr4MUulWsp7dMgEPEvCZp1Ca3BirYXCGkMUo4E82%2Bxf5uMsGdEK2fvxB2rlw5vERMNeDg4abxn0TlzoCPlqFgxIpWo71sRRTudvZHGs65V%2FVDaRnUXzf0KT%2Fe8BuwcsyvkXuCIPP8tH8XZk4Nf9wLNqZ%2FRcVDj1ZH5GqfUzroas0%2BitMFVvSPhJOPjmzIkuoIzjVLt2QUu%2B6oqergu%2BwN9LEnM5RW33fsky3aVGGDbyCHQ2dSM0i5IisqCxI9rpl1ip0wP%2Fko27HMmmezeWfqwxFcLArQaSzfOKfXijae7B%2FyGRYHaJQxtFGPI0yiDxIFaBZsYf6dwcL%2FEeRVe%2FUMQIR%2FRTIPoD%2BAVv7mY9TBBN42Fxa1yTe0eS8GWJR4byr7uuwek2LscPRFad36n3m%2B2NKKFJuPvXrTG03gPlwBAMckPYt5C7Cv95FisF7hnD6TK37StPAxk2xJBLB2CSykj9Uw5dXx3mJsn3Bz1tWlpV%2Fk6oU%2Btad5p1k3OYxlYHsA0okAwwufW9QU67AGlT2EG0upoAGFAM8u7UeyneNIF3CcZWdnbD%2Fa9Fn6dtyzkuY%2BVOdZEVtJkGe0m6irMAwZwZLRC8JdbJXPO%2F0w8OGmTgJRnx4%2FaiSMYGqtpZmZlHXq%2BzHgKbS0FfYqJvlrRRp0f6VS13yGLr0WFySbn3NmlyG6X0VhcXNDXj9ock8UQLXHJCsTonR82Z0paRekAM%2Bpr2LWBRXdBBkb%2Ba9rL%2Bjw%2BTWfu6krFTpt1FzFMFpje0Z8zsCNAQNCHoa7Qn%2BwYWSau79U4AwiGsuphM85FbIR6odwNFt%2BoGzXiqVHFqgCNKVjUFPKx7FxW4w%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200508T204420Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZZODAS4XD%2F20200508%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=9de13bf80aa13e896c8eaffedabdfd398631e40221d2b06a5c3cc11d99f5af3a [following]\n",
      "--2020-05-08 20:44:20--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt?response-content-disposition=attachment%3B%20filename%3D%22nvidia_ssdpyt_fp32_190826.pt%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJGMEQCIDTOcIMEjEOZCz8fE8A9VS52BuQxLfxHV5HjD2XMImILAiBBGPC5D%2FBlfMhB%2Bpe4bYj7mYlpOnoeNb4%2FIHSuAQ7Gpiq9Awjd%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMsVQ6WZTk70s2icTCKpED0yPq8kHJUawmVePhsCIr4MUulWsp7dMgEPEvCZp1Ca3BirYXCGkMUo4E82%2Bxf5uMsGdEK2fvxB2rlw5vERMNeDg4abxn0TlzoCPlqFgxIpWo71sRRTudvZHGs65V%2FVDaRnUXzf0KT%2Fe8BuwcsyvkXuCIPP8tH8XZk4Nf9wLNqZ%2FRcVDj1ZH5GqfUzroas0%2BitMFVvSPhJOPjmzIkuoIzjVLt2QUu%2B6oqergu%2BwN9LEnM5RW33fsky3aVGGDbyCHQ2dSM0i5IisqCxI9rpl1ip0wP%2Fko27HMmmezeWfqwxFcLArQaSzfOKfXijae7B%2FyGRYHaJQxtFGPI0yiDxIFaBZsYf6dwcL%2FEeRVe%2FUMQIR%2FRTIPoD%2BAVv7mY9TBBN42Fxa1yTe0eS8GWJR4byr7uuwek2LscPRFad36n3m%2B2NKKFJuPvXrTG03gPlwBAMckPYt5C7Cv95FisF7hnD6TK37StPAxk2xJBLB2CSykj9Uw5dXx3mJsn3Bz1tWlpV%2Fk6oU%2Btad5p1k3OYxlYHsA0okAwwufW9QU67AGlT2EG0upoAGFAM8u7UeyneNIF3CcZWdnbD%2Fa9Fn6dtyzkuY%2BVOdZEVtJkGe0m6irMAwZwZLRC8JdbJXPO%2F0w8OGmTgJRnx4%2FaiSMYGqtpZmZlHXq%2BzHgKbS0FfYqJvlrRRp0f6VS13yGLr0WFySbn3NmlyG6X0VhcXNDXj9ock8UQLXHJCsTonR82Z0paRekAM%2Bpr2LWBRXdBBkb%2Ba9rL%2Bjw%2BTWfu6krFTpt1FzFMFpje0Z8zsCNAQNCHoa7Qn%2BwYWSau79U4AwiGsuphM85FbIR6odwNFt%2BoGzXiqVHFqgCNKVjUFPKx7FxW4w%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200508T204420Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZZODAS4XD%2F20200508%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=9de13bf80aa13e896c8eaffedabdfd398631e40221d2b06a5c3cc11d99f5af3a\n",
      "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.128.160\n",
      "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.128.160|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 183409492 (175M) [application/octet-stream]\n",
      "Saving to: ‘nvidia_ssdpyt_fp32_190826.pt’\n",
      "\n",
      "nvidia_ssdpyt_fp32_ 100%[===================>] 174.91M  16.3MB/s    in 11s     \n",
      "\n",
      "2020-05-08 20:44:31 (16.2 MB/s) - ‘nvidia_ssdpyt_fp32_190826.pt’ saved [183409492/183409492]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "import tarfile\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from utils import dboxes300_coco, Encoder\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sess.default_bucket() # can replace with your own s3 bucket! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the necessary packages, we need to take the model file we downloaded and make it into a tarball. This is the format that Sagemaker needs the model to be in to deploy it to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('nvidia_ssdpyt_fp32_190826.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to upload this data to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = sess.upload_data(\n",
    "    path='model.tar.gz', bucket=bucket,\n",
    "    key_prefix='sagemaker-pytorch/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use the built in Jupyter magic command to write our transform_script.py. This file is going to tell our endpoint how to load our model, handle input data, and make predictions. We first initialize the model architecture, which is a SSD300 object detector based on a ResNet50 backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transform_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transform_script.py\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', backbone_path=None):\n",
    "        super().__init__()\n",
    "        if backbone == 'resnet18':\n",
    "            backbone = resnet18(pretrained=not backbone_path)\n",
    "            self.out_channels = [256, 512, 512, 256, 256, 128]\n",
    "        elif backbone == 'resnet34':\n",
    "            backbone = resnet34(pretrained=not backbone_path)\n",
    "            self.out_channels = [256, 512, 512, 256, 256, 256]\n",
    "        elif backbone == 'resnet50':\n",
    "            backbone = resnet50(pretrained=not backbone_path)\n",
    "            self.out_channels = [1024, 512, 512, 256, 256, 256]\n",
    "        elif backbone == 'resnet101':\n",
    "            backbone = resnet101(pretrained=not backbone_path)\n",
    "            self.out_channels = [1024, 512, 512, 256, 256, 256]\n",
    "        else:  # backbone == 'resnet152':\n",
    "            backbone = resnet152(pretrained=not backbone_path)\n",
    "            self.out_channels = [1024, 512, 512, 256, 256, 256]\n",
    "        if backbone_path:\n",
    "            backbone.load_state_dict(torch.load(backbone_path))\n",
    "\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(backbone.children())[:7])\n",
    "\n",
    "        conv4_block1 = self.feature_extractor[-1][0]\n",
    "\n",
    "        conv4_block1.conv1.stride = (1, 1)\n",
    "        conv4_block1.conv2.stride = (1, 1)\n",
    "        conv4_block1.downsample[0].stride = (1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x\n",
    "\n",
    "class SSD300(nn.Module):\n",
    "    def __init__(self, backbone=ResNet('resnet50')):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = backbone\n",
    "\n",
    "        self.label_num = 81  # number of COCO classes\n",
    "        self._build_additional_features(self.feature_extractor.out_channels)\n",
    "        self.num_defaults = [4, 6, 6, 6, 4, 4]\n",
    "        self.loc = []\n",
    "        self.conf = []\n",
    "\n",
    "        for nd, oc in zip(self.num_defaults, self.feature_extractor.out_channels):\n",
    "            self.loc.append(nn.Conv2d(oc, nd * 4, kernel_size=3, padding=1))\n",
    "            self.conf.append(nn.Conv2d(oc, nd * self.label_num, kernel_size=3, padding=1))\n",
    "\n",
    "        self.loc = nn.ModuleList(self.loc)\n",
    "        self.conf = nn.ModuleList(self.conf)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _build_additional_features(self, input_size):\n",
    "        self.additional_blocks = []\n",
    "        for i, (input_size, output_size, channels) in enumerate(zip(input_size[:-1], input_size[1:], [256, 256, 128, 128, 128])):\n",
    "            if i < 3:\n",
    "                layer = nn.Sequential(\n",
    "                    nn.Conv2d(input_size, channels, kernel_size=1, bias=False),\n",
    "                    nn.BatchNorm2d(channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(channels, output_size, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "                    nn.BatchNorm2d(output_size),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                )\n",
    "            else:\n",
    "                layer = nn.Sequential(\n",
    "                    nn.Conv2d(input_size, channels, kernel_size=1, bias=False),\n",
    "                    nn.BatchNorm2d(channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(channels, output_size, kernel_size=3, bias=False),\n",
    "                    nn.BatchNorm2d(output_size),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                )\n",
    "\n",
    "            self.additional_blocks.append(layer)\n",
    "\n",
    "        self.additional_blocks = nn.ModuleList(self.additional_blocks)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        layers = [*self.additional_blocks, *self.loc, *self.conf]\n",
    "        for layer in layers:\n",
    "            for param in layer.parameters():\n",
    "                if param.dim() > 1: nn.init.xavier_uniform_(param)\n",
    "\n",
    "    # Shape the classifier to the view of bboxes\n",
    "    def bbox_view(self, src, loc, conf):\n",
    "        ret = []\n",
    "        for s, l, c in zip(src, loc, conf):\n",
    "            ret.append((l(s).view(s.size(0), 4, -1), c(s).view(s.size(0), self.label_num, -1)))\n",
    "\n",
    "        locs, confs = list(zip(*ret))\n",
    "        locs, confs = torch.cat(locs, 2).contiguous(), torch.cat(confs, 2).contiguous()\n",
    "        return locs, confs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        detection_feed = [x]\n",
    "        for l in self.additional_blocks:\n",
    "            x = l(x)\n",
    "            detection_feed.append(x)\n",
    "\n",
    "        # Feature Map 38x38x4, 19x19x6, 10x10x6, 5x5x6, 3x3x4, 1x1x4\n",
    "        locs, confs = self.bbox_view(detection_feed, self.loc, self.conf)\n",
    "\n",
    "        # For SSD 300, shall return nbatch x 8732 x {nlabels, nlocs} results\n",
    "        return locs, confs\n",
    "\n",
    "# this function tells the endpoitn how to make predictions and how to package them to send back\n",
    "def predict_fn(input_data, model):\n",
    "    # run prediction\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_data)\n",
    "    pred_dict = {'pred1':pred[0].detach().cpu().numpy(),'pred2':pred[1].detach().cpu().numpy()}\n",
    "    return pred_dict\n",
    "        \n",
    "# this function loads our model from s3, or if that fails, from the NGC repo\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SSD300(backbone=ResNet('resnet50'))\n",
    "    try:\n",
    "        model_weights = torch.load(os.path.join(model_dir, 'nvidia_ssdpyt_fp32_190826.pt'), map_location='cpu')['model']\n",
    "        model.to('cpu')\n",
    "        model.load_state_dict(model_weights)\n",
    "    except:\n",
    "        print('using fallback model loading')\n",
    "        os.system('wget https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt')\n",
    "        model_weights = torch.load(os.path.join('nvidia_ssdpyt_fp32_190826.pt'), map_location='cpu')['model']\n",
    "        model.to('cpu')\n",
    "        model.load_state_dict(model_weights)\n",
    "    model.eval()\n",
    "    return model \n",
    "\n",
    "# this function handles our input data and reshapes it back into an image\n",
    "def input_fn(request_body, request_content_type):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if(request_content_type == 'application/x-npy'):\n",
    "        try:\n",
    "            input_data = np.frombuffer(request_body, dtype=int)\n",
    "        except:\n",
    "            input_data = np.array(request_body, dtype=int)\n",
    "    try:\n",
    "        input_data = torch.tensor(np.reshape(input_data,(1,3,300,300)), dtype=torch.float32, device=device) # this needs to be a torch tensor \n",
    "    except:\n",
    "        input_data = torch.tensor(np.reshape(input_data[16:],(1,3,300,300)), dtype=torch.float32, device=device) # this needs to be a torch tensor \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SageMaker PyTorchModel to instantiate and deploy the model onto a GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "pytorch_model = PyTorchModel(model_data=modelpath, role=role,\n",
    "                             entry_point='transform_script.py',\n",
    "                             framework_version='1.4.0')\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.g4dn.4xlarge',\n",
    "                                 initial_instance_count=1,\n",
    "                                 wait=True,\n",
    "                                 endpoint_name='torch-ssd-ngc-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download, convert and send images for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uris = [\n",
    "    'http://images.cocodataset.org/val2017/000000397133.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000037777.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000252219.jpg'\n",
    "]\n",
    "\n",
    "img = imread('https://upload.wikimedia.org/wikipedia/commons/2/25/Postmen_Office_Room.jpg')\n",
    "img  = resize(img, (300,300,3))\n",
    "img = np.array(img, dtype=np.int64)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'pred1': array([[[ 0.38952032, -0.02861576, -0.04215011, ..., -0.14958134,\n",
       "          0.00432905, -0.12932765],\n",
       "        [ 0.09118789,  0.04212354, -0.14801054, ...,  0.19097322,\n",
       "          0.26461983,  0.18199176],\n",
       "        [-2.2925906 , -1.8833055 , -1.5824505 , ..., -0.08838636,\n",
       "         -0.13544835,  2.1892743 ],\n",
       "        [-0.87224966, -0.71586657, -0.696971  , ..., -0.16525826,\n",
       "          1.9327695 , -0.3432234 ]]], dtype=float32), 'pred2': array([[[ 8.178115  ,  8.464893  ,  8.17106   , ...,  7.6592464 ,\n",
       "          7.431782  ,  7.3305855 ],\n",
       "        [ 1.4540417 ,  1.6984062 ,  1.5541288 , ...,  2.1266382 ,\n",
       "          2.3925123 ,  2.0987399 ],\n",
       "        [-0.7406039 , -0.6521972 , -0.5834959 , ..., -0.9978748 ,\n",
       "         -0.95666707, -1.0767772 ],\n",
       "        ...,\n",
       "        [-0.48175845, -0.5065458 , -0.3991172 , ..., -0.12805915,\n",
       "         -0.19128259, -0.16708916],\n",
       "        [-0.5146159 , -0.625941  , -0.57805604, ..., -1.3090948 ,\n",
       "         -1.3886985 , -1.2481947 ],\n",
       "        [-0.13825768, -0.08807708,  0.0310629 , ..., -0.3747707 ,\n",
       "         -0.46389207, -0.32038376]]], dtype=float32)}, dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predictor.predict(img.tobytes())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dboxes = dboxes300_coco()\n",
    "# encoder = Encoder(dboxes)\n",
    "# ploc, plabel = [val.float() for val in prediction]\n",
    "# encoded = encoder.decode_batch(ploc, plabel, criteria=0.5, max_output=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove model and delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm nvidia_ssdpyt_fp32_190826.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
