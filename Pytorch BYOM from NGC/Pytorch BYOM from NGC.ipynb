{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are you looking for a way to quickly deploy a very accurate and fast model to an endpoint for object detection? \n",
    "\n",
    "### Then you can download an NVIDIA model from torchhub\n",
    "\n",
    "### ... and then compress it as a tar.gz file, and use this for deployment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a description of the model you can look here: https://ngc.nvidia.com/catalog/model-scripts/nvidia:ssd_for_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 15:18:11--  https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 54.186.237.130, 52.38.124.212\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|54.186.237.130|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt?response-content-disposition=attachment%3B%20filename%3D%22nvidia_ssdpyt_fp32_190826.pt%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIEhH6UE%2B4dwdh6c3f0ozxtukrIELAPzhZbulm%2FFM4HG9AiEAk4i9Ma1vLvcEH%2BCS2U8yjAzsZYS30QtNaz%2FgeNymL2IqvQMI2P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgw3ODkzNjMxMzUwMjciDFl0SqiAYetAhbbk3CqRAwespBw4o2BBbmxIaTXNWcDP83wFP0ytAaR7lUTxCP0rDzOGIFcB9MqoVXR3BWzmroJ3uDldZVesoOijm7detmeIS141z6zewFFp0UnDVJGzI31pEW5BdWda4Qz133olOSYXkJmyHhfL9LZ7d2xpsaLl4D7BN6rRVmYRlUChFhWt9BMflOaK8i9cEfqei%2Fgui5BPlBu%2FlhvkzUXsSZHviL71vLBknJ02ikQ88QrO14pE0StkzUPTOR8rjskk2oAjSW7CXXcmFp30jis5Bdxsq1lepPsXEb18cwZkckmBJVNb3UcGODelf4cfcv%2FRiYWWY%2B3GYHUL4%2Bbvv9482OwSNxkK8Gcy6Xg6aKTVXD2tOi1gB1mKbzGEzs8LZ5oZTcC82GoB1n%2BaygrlLkQlB8JYOOVkofRX8Amhe6b00%2FB7MocHp%2Fq2ZO%2FczDDpoSNRJvbdzTkYfQFr56w8JUkKIeCmM6ZZbDjQucEbFqSb5YYqYDDLKaL8HB8u%2FjcXNk7WCSGlbRi%2BZKoIbzZMrfdp2u54HH%2BBMPDa1fUFOusBAnhRp%2BB9TCR%2BSxKbZLehhZGVyFedyvTwR7A0oIwm8jndh997Csx%2FaeKaR9Ae7vU0EMRTzEhJHhqbfYK7rOjs8eteOs098wuKyo%2Fm7Yka5egHdLuOfcrHoueZQi7kn4daBAHb5ZyaSSl4HWjcLejbPiJ3ZEiafTcoWA%2BiaU3d4vjkdCxKzKIkeroOSmIsY%2FEz0Q62VSE8m06%2BELweXtoLU3R%2F0jKyJvugMQRrlT7s6IdhIBsnVEh4GDS0j3Fd0KJoA3boA%2F2i5oD%2BPVoy7%2FyxiTMV9ZEJG0aw23jGzhzzmJXesv7lPJ9A2VN%2B8A%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200508T151811Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZZD7GCQ6I%2F20200508%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=eeefe5e5be78776a979f3336099e9857037ee78f7d75fe06e509e507ee7b4561 [following]\n",
      "--2020-05-08 15:18:11--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt?response-content-disposition=attachment%3B%20filename%3D%22nvidia_ssdpyt_fp32_190826.pt%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIEhH6UE%2B4dwdh6c3f0ozxtukrIELAPzhZbulm%2FFM4HG9AiEAk4i9Ma1vLvcEH%2BCS2U8yjAzsZYS30QtNaz%2FgeNymL2IqvQMI2P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgw3ODkzNjMxMzUwMjciDFl0SqiAYetAhbbk3CqRAwespBw4o2BBbmxIaTXNWcDP83wFP0ytAaR7lUTxCP0rDzOGIFcB9MqoVXR3BWzmroJ3uDldZVesoOijm7detmeIS141z6zewFFp0UnDVJGzI31pEW5BdWda4Qz133olOSYXkJmyHhfL9LZ7d2xpsaLl4D7BN6rRVmYRlUChFhWt9BMflOaK8i9cEfqei%2Fgui5BPlBu%2FlhvkzUXsSZHviL71vLBknJ02ikQ88QrO14pE0StkzUPTOR8rjskk2oAjSW7CXXcmFp30jis5Bdxsq1lepPsXEb18cwZkckmBJVNb3UcGODelf4cfcv%2FRiYWWY%2B3GYHUL4%2Bbvv9482OwSNxkK8Gcy6Xg6aKTVXD2tOi1gB1mKbzGEzs8LZ5oZTcC82GoB1n%2BaygrlLkQlB8JYOOVkofRX8Amhe6b00%2FB7MocHp%2Fq2ZO%2FczDDpoSNRJvbdzTkYfQFr56w8JUkKIeCmM6ZZbDjQucEbFqSb5YYqYDDLKaL8HB8u%2FjcXNk7WCSGlbRi%2BZKoIbzZMrfdp2u54HH%2BBMPDa1fUFOusBAnhRp%2BB9TCR%2BSxKbZLehhZGVyFedyvTwR7A0oIwm8jndh997Csx%2FaeKaR9Ae7vU0EMRTzEhJHhqbfYK7rOjs8eteOs098wuKyo%2Fm7Yka5egHdLuOfcrHoueZQi7kn4daBAHb5ZyaSSl4HWjcLejbPiJ3ZEiafTcoWA%2BiaU3d4vjkdCxKzKIkeroOSmIsY%2FEz0Q62VSE8m06%2BELweXtoLU3R%2F0jKyJvugMQRrlT7s6IdhIBsnVEh4GDS0j3Fd0KJoA3boA%2F2i5oD%2BPVoy7%2FyxiTMV9ZEJG0aw23jGzhzzmJXesv7lPJ9A2VN%2B8A%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200508T151811Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZZD7GCQ6I%2F20200508%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=eeefe5e5be78776a979f3336099e9857037ee78f7d75fe06e509e507ee7b4561\n",
      "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.224.168\n",
      "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.224.168|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 183409492 (175M) [application/octet-stream]\n",
      "Saving to: ‘nvidia_ssdpyt_fp32_190826.pt’\n",
      "\n",
      "nvidia_ssdpyt_fp32_ 100%[===================>] 174.91M  15.9MB/s    in 10s     \n",
      "\n",
      "2020-05-08 15:18:22 (17.5 MB/s) - ‘nvidia_ssdpyt_fp32_190826.pt’ saved [183409492/183409492]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "import tarfile\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from utils import dboxes300_coco, Encoder\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sess.default_bucket() # can replace with your own s3 bucket! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the necessary packages, we need to take the model file we downloaded and make it into a tarball. This is the format that Sagemaker needs the model to be in to deploy it to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('nvidia_ssdpyt_fp32_190826.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to upload this data to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = sess.upload_data(\n",
    "    path='model.tar.gz', bucket=bucket,\n",
    "    key_prefix='sagemaker-pytorch/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use the built in Jupyter magic command to write our transform_script.py. This file is going to tell our endpoint how to load our model, handle input data, and make predictions. We first initialize the model architecture, which is a SSD300 object detector based on a ResNet50 backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transform_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transform_script.py\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', backbone_path=None):\n",
    "        super().__init__()\n",
    "        if backbone == 'resnet18':\n",
    "            backbone = resnet18(pretrained=not backbone_path)\n",
    "            self.out_channels = [256, 512, 512, 256, 256, 128]\n",
    "        elif backbone == 'resnet34':\n",
    "            backbone = resnet34(pretrained=not backbone_path)\n",
    "            self.out_channels = [256, 512, 512, 256, 256, 256]\n",
    "        elif backbone == 'resnet50':\n",
    "            backbone = resnet50(pretrained=not backbone_path)\n",
    "            self.out_channels = [1024, 512, 512, 256, 256, 256]\n",
    "        elif backbone == 'resnet101':\n",
    "            backbone = resnet101(pretrained=not backbone_path)\n",
    "            self.out_channels = [1024, 512, 512, 256, 256, 256]\n",
    "        else:  # backbone == 'resnet152':\n",
    "            backbone = resnet152(pretrained=not backbone_path)\n",
    "            self.out_channels = [1024, 512, 512, 256, 256, 256]\n",
    "        if backbone_path:\n",
    "            backbone.load_state_dict(torch.load(backbone_path))\n",
    "\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(backbone.children())[:7])\n",
    "\n",
    "        conv4_block1 = self.feature_extractor[-1][0]\n",
    "\n",
    "        conv4_block1.conv1.stride = (1, 1)\n",
    "        conv4_block1.conv2.stride = (1, 1)\n",
    "        conv4_block1.downsample[0].stride = (1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x\n",
    "\n",
    "class SSD300(nn.Module):\n",
    "    def __init__(self, backbone=ResNet('resnet50')):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = backbone\n",
    "\n",
    "        self.label_num = 81  # number of COCO classes\n",
    "        self._build_additional_features(self.feature_extractor.out_channels)\n",
    "        self.num_defaults = [4, 6, 6, 6, 4, 4]\n",
    "        self.loc = []\n",
    "        self.conf = []\n",
    "\n",
    "        for nd, oc in zip(self.num_defaults, self.feature_extractor.out_channels):\n",
    "            self.loc.append(nn.Conv2d(oc, nd * 4, kernel_size=3, padding=1))\n",
    "            self.conf.append(nn.Conv2d(oc, nd * self.label_num, kernel_size=3, padding=1))\n",
    "\n",
    "        self.loc = nn.ModuleList(self.loc)\n",
    "        self.conf = nn.ModuleList(self.conf)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _build_additional_features(self, input_size):\n",
    "        self.additional_blocks = []\n",
    "        for i, (input_size, output_size, channels) in enumerate(zip(input_size[:-1], input_size[1:], [256, 256, 128, 128, 128])):\n",
    "            if i < 3:\n",
    "                layer = nn.Sequential(\n",
    "                    nn.Conv2d(input_size, channels, kernel_size=1, bias=False),\n",
    "                    nn.BatchNorm2d(channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(channels, output_size, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "                    nn.BatchNorm2d(output_size),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                )\n",
    "            else:\n",
    "                layer = nn.Sequential(\n",
    "                    nn.Conv2d(input_size, channels, kernel_size=1, bias=False),\n",
    "                    nn.BatchNorm2d(channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(channels, output_size, kernel_size=3, bias=False),\n",
    "                    nn.BatchNorm2d(output_size),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                )\n",
    "\n",
    "            self.additional_blocks.append(layer)\n",
    "\n",
    "        self.additional_blocks = nn.ModuleList(self.additional_blocks)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        layers = [*self.additional_blocks, *self.loc, *self.conf]\n",
    "        for layer in layers:\n",
    "            for param in layer.parameters():\n",
    "                if param.dim() > 1: nn.init.xavier_uniform_(param)\n",
    "\n",
    "    # Shape the classifier to the view of bboxes\n",
    "    def bbox_view(self, src, loc, conf):\n",
    "        ret = []\n",
    "        for s, l, c in zip(src, loc, conf):\n",
    "            ret.append((l(s).view(s.size(0), 4, -1), c(s).view(s.size(0), self.label_num, -1)))\n",
    "\n",
    "        locs, confs = list(zip(*ret))\n",
    "        locs, confs = torch.cat(locs, 2).contiguous(), torch.cat(confs, 2).contiguous()\n",
    "        return locs, confs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        detection_feed = [x]\n",
    "        for l in self.additional_blocks:\n",
    "            x = l(x)\n",
    "            detection_feed.append(x)\n",
    "\n",
    "        # Feature Map 38x38x4, 19x19x6, 10x10x6, 5x5x6, 3x3x4, 1x1x4\n",
    "        locs, confs = self.bbox_view(detection_feed, self.loc, self.conf)\n",
    "\n",
    "        # For SSD 300, shall return nbatch x 8732 x {nlabels, nlocs} results\n",
    "        return locs, confs\n",
    "\n",
    "# this function tells the endpoitn how to make predictions and how to package them to send back\n",
    "def predict_fn(input_data, model):\n",
    "    # run prediction\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_data)\n",
    "    pred_dict = {'pred1':pred[0].detach().cpu().numpy(),'pred2':pred[1].detach().cpu().numpy()}\n",
    "    return pred_dict\n",
    "        \n",
    "# this function loads our model from s3, or if that fails, from the NGC repo\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SSD300(backbone=ResNet('resnet50'))\n",
    "    try:\n",
    "        model_weights = torch.load(os.path.join(model_dir, 'nvidia_ssdpyt_fp32_190826.pt'), map_location='cpu')['model']\n",
    "        model.to('cpu')\n",
    "        model.load_state_dict(model_weights)\n",
    "    except:\n",
    "        print('using fallback model loading')\n",
    "        os.system('wget https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt')\n",
    "        model_weights = torch.load(os.path.join('nvidia_ssdpyt_fp32_190826.pt'), map_location='cpu')['model']\n",
    "        model.to('cpu')\n",
    "        model.load_state_dict(model_weights)\n",
    "    model.eval()\n",
    "    return model \n",
    "\n",
    "# this function handles our input data and reshapes it back into an image\n",
    "def input_fn(request_body, request_content_type):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if(request_content_type == 'application/x-npy'):\n",
    "        try:\n",
    "            input_data = np.frombuffer(request_body, dtype=int)\n",
    "        except:\n",
    "            input_data = np.array(request_body, dtype=int)\n",
    "    try:\n",
    "        input_data = torch.tensor(np.reshape(input_data,(1,3,300,300)), dtype=torch.float32, device=device) # this needs to be a torch tensor \n",
    "    except:\n",
    "        input_data = torch.tensor(np.reshape(input_data[16:],(1,3,300,300)), dtype=torch.float32, device=device) # this needs to be a torch tensor \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "pytorch_model = PyTorchModel(model_data=modelpath, role=role,\n",
    "                             entry_point='transform_script.py',\n",
    "                             framework_version='1.4.0')\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.g4dn.4xlarge', initial_instance_count=1, wait=True,endpoint_name='torch-ssd-ngc-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uris = [\n",
    "    'http://images.cocodataset.org/val2017/000000397133.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000037777.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000252219.jpg'\n",
    "]\n",
    "\n",
    "img = imread('https://upload.wikimedia.org/wikipedia/commons/2/25/Postmen_Office_Room.jpg')\n",
    "img  = resize(img, (300,300,3))\n",
    "img = np.array(img, dtype=np.int64)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(img.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dboxes = dboxes300_coco()\n",
    "encoder = Encoder(dboxes)\n",
    "ploc, plabel = [val.float() for val in prediction]\n",
    "encoded = encoder.decode_batch(ploc, plabel, criteria=0.5, max_output=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(result.tolist()['pred2'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 81, 8732)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tolist()['pred2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 8732)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tolist()['pred1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09118789,  0.04212354, -0.14801054, ...,  0.19097322,\n",
       "        0.26461983,  0.18199176], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tolist()['pred1'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4540417, 1.6984062, 1.5541288, ..., 2.1266382, 2.3925123,\n",
       "       2.0987399], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tolist()['pred2'][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also, you can download the model from torchhub with this API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ec2-user/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/ec2-user/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcab6f7575f455b98605a27acd6a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/1/files/nvidia_ssdpyt_fp32_20190225.pt\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or better, download the model from torch hub on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transform_script_hub.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transform_script_hub.py\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from six import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math='fp32',map_location='gpu')\n",
    "    return model\n",
    "                       \n",
    "def input_fn(request_body, request_content_type):\n",
    "    return torch.load(BytesIO(request_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp\n",
      "-----------------!"
     ]
    }
   ],
   "source": [
    "#PyTorchModel requires a non-empty, model_data file\n",
    "\n",
    "!echo \"tmp content\" > tmp\n",
    "!tar -zcvf ./tmp.tar.gz tmp\n",
    "pytorch_model = PyTorchModel(model_data = 'file://tmp.tar.gz',\n",
    "                             role=role,\n",
    "                             entry_point='./transform_script_hub.py',\n",
    "                             framework_version='1.4.0')\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.p3.2xlarge',\n",
    "                                 initial_instance_count=1,\n",
    "                                 endpoint_name='nvidia-ssd-pytorch-gpu2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
